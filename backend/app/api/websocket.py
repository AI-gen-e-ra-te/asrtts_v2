import os
import json
import base64
import asyncio
import uuid
import subprocess
import tempfile
from pathlib import Path
from fastapi import APIRouter, WebSocket, WebSocketDisconnect
from app.core.asr import transcribe_audio
from app.core.llm import chat_stream
from app.core.tts import text_to_speech
import soundfile as sf
import io

router = APIRouter()

async def convert_audio_to_wav(input_path: str, output_path: str = None) -> str:
    """
    å°†éŸ³é¢‘æ–‡ä»¶è½¬æ¢ä¸º WAV æ ¼å¼ï¼Œæ”¯æŒå¤šç§æ–¹æ³•
    è¿”å›è½¬æ¢åçš„ WAV æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å›åŸå§‹æ–‡ä»¶è·¯å¾„
    """
    if output_path is None:
        output_path = input_path.replace(".webm", ".wav").replace(".mp3", ".wav").replace(".ogg", ".wav")

    # æ–¹æ³•1: ä½¿ç”¨æœ¬åœ° ffmpeg å·¥å…·
    project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    local_ffmpeg = os.path.join(project_root, "tools", "ffmpeg", "ffmpeg.exe")
    ffmpeg_cmd = local_ffmpeg if os.path.exists(local_ffmpeg) else "ffmpeg"

    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”å¤§å°åˆç†
    if not os.path.exists(input_path):
        print(f"âŒ Input file does not exist: {input_path}")
    else:
        file_size = os.path.getsize(input_path)
        if file_size < 1024:  # å°äº1KBçš„æ–‡ä»¶å¯èƒ½æ— æ•ˆ
            print(f"âš ï¸ Input file too small ({file_size} bytes), may be invalid")

    # é‡è¯•æœºåˆ¶
    max_retries = 2
    for attempt in range(max_retries):
        try:
            # å°è¯•ä½¿ç”¨ ffmpeg è½¬æ¢
            subprocess.run(
                [ffmpeg_cmd, "-y", "-i", input_path, "-ac", "1", "-ar", "16000", output_path],
                check=True,
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
                timeout=30
            )
            print(f"âœ… FFmpeg conversion successful (attempt {attempt+1}/{max_retries}): {input_path} -> {output_path}")
            return output_path
        except (subprocess.TimeoutExpired, subprocess.CalledProcessError, FileNotFoundError, OSError) as e:
            print(f"âš ï¸ FFmpeg conversion failed (attempt {attempt+1}/{max_retries}): {e}")
            if attempt == max_retries - 1:
                print(f"âŒ All ffmpeg attempts failed")
            else:
                # ç­‰å¾…ç‰‡åˆ»åé‡è¯•
                import time
                time.sleep(0.5)

    # æ–¹æ³•2: å°è¯•ä½¿ç”¨ pydub (å¦‚æœå¯ç”¨)
    try:
        # è®¾ç½® pydub ä½¿ç”¨çš„ ffmpeg è·¯å¾„
        import pydub
        # ç¡®ä¿ä½¿ç”¨æˆ‘ä»¬æœ¬åœ°çš„ ffmpeg
        project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
        local_ffmpeg_dir = os.path.join(project_root, "tools", "ffmpeg")
        local_ffmpeg = os.path.join(local_ffmpeg_dir, "ffmpeg.exe")
        local_ffprobe = os.path.join(local_ffmpeg_dir, "ffprobe.exe")

        # è®¾ç½®ç¯å¢ƒå˜é‡å’Œ pydub é…ç½®
        os.environ["PATH"] = local_ffmpeg_dir + os.pathsep + os.environ.get("PATH", "")
        pydub.AudioSegment.converter = local_ffmpeg
        pydub.AudioSegment.ffprobe = local_ffprobe if os.path.exists(local_ffprobe) else None

        from pydub import AudioSegment
        # å°è¯•æ ¹æ®æ‰©å±•åè¯»å–
        ext = os.path.splitext(input_path)[1].lower()
        if ext == ".webm":
            audio = AudioSegment.from_file(input_path, format="webm")
        elif ext == ".mp3":
            audio = AudioSegment.from_file(input_path, format="mp3")
        else:
            # å°è¯•è‡ªåŠ¨æ£€æµ‹
            audio = AudioSegment.from_file(input_path)

        # è½¬æ¢ä¸ºå•å£°é“ï¼Œ16000Hzé‡‡æ ·ç‡
        audio = audio.set_channels(1).set_frame_rate(16000)
        audio.export(output_path, format="wav")
        print(f"âœ… Pydub conversion successful: {input_path} -> {output_path}")
        return output_path
    except Exception as e:
        print(f"âš ï¸ Pydub conversion failed: {e}")
        import traceback
        traceback.print_exc()

    # æ–¹æ³•3: å¦‚æœåŸå§‹æ–‡ä»¶å·²ç»æ˜¯.wavæˆ–æ— æ³•è½¬æ¢ï¼Œè¿”å›åŸå§‹è·¯å¾„
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ
    if input_path.lower().endswith('.wav'):
        try:
            # éªŒè¯WAVæ–‡ä»¶æ˜¯å¦å¯ä»¥è¯»å–
            data, samplerate = sf.read(input_path)
            print(f"âœ… Using original WAV file: {input_path}")
            return input_path
        except Exception as e:
            print(f"âŒ WAV file validation failed: {e}")

    # æ–¹æ³•4: å°è¯•ä½¿ç”¨ torchaudio (å¦‚æœå¯ç”¨)
    try:
        import torchaudio
        # ä½¿ç”¨ torchaudio åŠ è½½å¹¶ä¿å­˜ä¸º WAV
        waveform, sample_rate = torchaudio.load(input_path)
        # è½¬æ¢ä¸ºå•å£°é“ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if waveform.shape[0] > 1:
            waveform = waveform.mean(dim=0, keepdim=True)
        # é‡é‡‡æ ·åˆ° 16000 Hzï¼ˆå¦‚æœéœ€è¦ï¼‰
        if sample_rate != 16000:
            resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)
            waveform = resampler(waveform)
        # ä¿å­˜ä¸º WAV
        torchaudio.save(output_path, waveform, 16000)
        print(f"âœ… Torchaudio conversion successful: {input_path} -> {output_path}")
        return output_path
    except Exception as e:
        print(f"âš ï¸ Torchaudio conversion failed: {e}")
        import traceback
        traceback.print_exc()

    # æ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥
    print(f"âŒ All audio conversion methods failed for: {input_path}")
    return None

@router.websocket("/ws/chat")
async def websocket_endpoint(websocket: WebSocket):
    """
    å¤„ç†å…¨åŒå·¥è¯­éŸ³å¯¹è¯çš„ WebSocket ç«¯ç‚¹
    """
    await websocket.accept()
    client_id = str(uuid.uuid4())[:8] # ç»™æ¯ä¸ªè¿æ¥ç”Ÿæˆä¸€ä¸ªçŸ­IDæ–¹ä¾¿æ—¥å¿—æŸ¥çœ‹
    print(f"ğŸ”Œ Client connected: {client_id}")

    # ç”¨äºæš‚å­˜æ¥æ”¶åˆ°çš„éŸ³é¢‘åˆ‡ç‰‡
    audio_buffer = bytearray()

    # å¯¹è¯å†å²ç®¡ç†ï¼ˆç»´æŠ¤ä¸Šä¸‹æ–‡ï¼‰
    message_history = [
        {"role": "system", "content": "You are a helpful voice assistant. Please keep your replies concise, short, and conversational suitable for TTS."}
    ]
    MAX_HISTORY_TURNS = 10  # æœ€å¤šä¿ç•™10è½®å¯¹è¯ï¼ˆ20æ¡æ¶ˆæ¯ï¼‰

    def add_to_history(role: str, content: str):
        """æ·»åŠ æ¶ˆæ¯åˆ°å†å²ï¼Œå¹¶ä¿®å‰ªè¶…è¿‡é™åˆ¶çš„æ—§æ¶ˆæ¯"""
        message_history.append({"role": role, "content": content})
        # ä¿ç•™æœ€è¿‘çš„ MAX_HISTORY_TURNS*2 æ¡æ¶ˆæ¯ï¼ˆæ¯è½®å¯¹è¯2æ¡ï¼‰
        while len(message_history) > MAX_HISTORY_TURNS * 2 + 1:  # +1 ä¸ºsystemæ¶ˆæ¯
            # åˆ é™¤æœ€æ—§çš„ç”¨æˆ·/åŠ©æ‰‹æ¶ˆæ¯ï¼ˆè·³è¿‡systemæ¶ˆæ¯ï¼‰
            if len(message_history) > 1:
                removed = message_history.pop(1)  # ç§»é™¤systemä¹‹åçš„ç¬¬ä¸€æ¡æ¶ˆæ¯
                print(f"ğŸ“ [{client_id}] Removed old message from history: {removed['role']}")

    try:
        while True:
            data = await websocket.receive_text()
            try:
                message = json.loads(data)
            except json.JSONDecodeError:
                print(f"âŒ [{client_id}] Invalid JSON received")
                continue

            if "type" not in message:
                print(f"âŒ [{client_id}] Message missing 'type' field")
                continue
            
            if message["type"] == "audio-chunk":
                chunk = base64.b64decode(message["content"])
                audio_buffer.extend(chunk)
            
            elif message["type"] == "text-input":
                # å¤„ç†æ–‡æœ¬è¾“å…¥
                user_text = message.get("content", "").strip()
                if not user_text:
                    continue

                print(f"ğŸ‘¤ [{client_id}] User text: {user_text}")

                # å‘é€ç”¨æˆ·æ¶ˆæ¯ç»™å‰ç«¯
                await websocket.send_json({
                    "type": "user-message",
                    "content": user_text
                })

                # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å¯¹è¯å†å²
                add_to_history("user", user_text)

                # é€šçŸ¥å‰ç«¯å¤„ç†ä¸­
                await websocket.send_json({"type": "status", "content": "processing"})

                # å¤„ç†LLMå“åº”ï¼ˆä½¿ç”¨å®Œæ•´çš„å¯¹è¯å†å²ï¼‰
                sentence_buffer = ""
                full_response = ""  # æ”¶é›†å®Œæ•´å›å¤ä»¥ä¾¿æ·»åŠ åˆ°å†å²
                punctuation = {",", "ï¼Œ", ".", "ã€‚", "?", "ï¼Ÿ", "!", "ï¼", ";", "ï¼›", ":", "ï¼š", "\n"}

                try:
                    async for char in chat_stream(message_history):
                        # å®æ—¶æ¨æµæ–‡å­—
                        await websocket.send_json({"type": "text-update", "content": char})

                        sentence_buffer += char
                        full_response += char

                        # æ–­å¥
                        if char in punctuation:
                            if len(sentence_buffer.strip()) > 1:
                                print(f"ğŸ—£ï¸ [{client_id}] Synthesizing: {sentence_buffer}")
                                audio_base64 = await text_to_speech(sentence_buffer)

                                if audio_base64:
                                    await websocket.send_json({
                                        "type": "audio-chunk",
                                        "content": audio_base64
                                    })
                                sentence_buffer = ""

                    # å¤„ç†å‰©ä½™æ–‡æœ¬
                    if sentence_buffer.strip():
                         print(f"ğŸ—£ï¸ [{client_id}] Synthesizing (Final): {sentence_buffer}")
                         audio_base64 = await text_to_speech(sentence_buffer)
                         if audio_base64:
                            await websocket.send_json({
                                "type": "audio-chunk",
                                "content": audio_base64
                            })

                    # å°†åŠ©æ‰‹å›å¤æ·»åŠ åˆ°å¯¹è¯å†å²
                    if full_response.strip():
                        add_to_history("assistant", full_response.strip())
                        print(f"ğŸ“ [{client_id}] Added assistant response to history ({len(full_response)} chars)")

                except Exception as e:
                    print(f"âŒ LLM/TTS Process Error: {e}")
                    await websocket.send_json({"type": "text-update", "content": f"\n[Error: {str(e)}]"})

                await websocket.send_json({"type": "status", "content": "idle"})
            
            elif message["type"] == "audio-end":
                # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶åå¹¶ä¿å­˜
                request_id = str(uuid.uuid4())
                temp_audio_path = f"temp_input_{request_id}.webm"

                # æ£€æŸ¥éŸ³é¢‘æ•°æ®æ˜¯å¦æœ‰æ•ˆï¼ˆæœ€å°é•¿åº¦æ£€æŸ¥ï¼‰
                if len(audio_buffer) < 1024:  # è‡³å°‘1KBçš„éŸ³é¢‘æ•°æ®
                    print(f"âš ï¸ Audio buffer too small ({len(audio_buffer)} bytes), skipping ASR")
                    # æ¸…ç©ºç¼“å†²åŒºå¹¶è·³è¿‡
                    audio_buffer = bytearray()
                    await websocket.send_json({"type": "status", "content": "idle"})
                    continue

                # å†™å…¥æ–‡ä»¶
                with open(temp_audio_path, "wb") as f:
                    f.write(audio_buffer)

                # æ¸…ç©ºç¼“å†²åŒº
                audio_buffer = bytearray()

                # é€šçŸ¥å‰ç«¯
                await websocket.send_json({"type": "status", "content": "processing"})

                # è½¬æ¢éŸ³é¢‘æ ¼å¼ (WebM -> WAV) ä»¥è§£å†³ EBML header parsing failed é—®é¢˜
                # æµè§ˆå™¨å½•åˆ¶çš„ WebM æœ‰æ—¶æ²¡æœ‰å®Œæ•´çš„ Headerï¼Œä½¿ç”¨å¤šé‡å¤‡é€‰æ–¹æ¡ˆ
                wav_path = temp_audio_path.replace(".webm", ".wav")

                # ä½¿ç”¨å¢å¼ºçš„éŸ³é¢‘è½¬æ¢å‡½æ•°
                asr_input_path = await convert_audio_to_wav(temp_audio_path, wav_path)

                if asr_input_path is None:
                    print(f"âŒ All audio conversion methods failed, skipping ASR")
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    if os.path.exists(temp_audio_path):
                        os.remove(temp_audio_path)
                    audio_buffer = bytearray()
                    await websocket.send_json({"type": "status", "content": "idle"})
                    continue

                # ASR
                try:
                    # ä½¿ç”¨ asyncio.to_thread è¿è¡ŒåŒæ­¥çš„ Whisper è¯†åˆ«
                    user_text = await asyncio.to_thread(transcribe_audio, asr_input_path)
                    print(f"ğŸ‘‚ [{client_id}] User said: {user_text}")
                except Exception as e:
                    print(f"âŒ ASR Error: {e}")
                    user_text = ""
                
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if os.path.exists(temp_audio_path):
                    os.remove(temp_audio_path)
                if os.path.exists(wav_path):
                    os.remove(wav_path)

                # å¦‚æœæ²¡å¬åˆ°è¯´è¯ï¼Œç›´æ¥è·³è¿‡
                if not user_text.strip():
                    await websocket.send_json({"type": "status", "content": "idle"})
                    continue

                # å‘é€ç”¨æˆ·æ¶ˆæ¯ç»™å‰ç«¯ï¼ˆä½¿ç”¨æ–°çš„æ¶ˆæ¯ç±»å‹ï¼‰
                await websocket.send_json({
                    "type": "user-message",
                    "content": user_text
                })

                # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å¯¹è¯å†å²
                add_to_history("user", user_text)

                sentence_buffer = ""
                full_response = ""  # æ”¶é›†å®Œæ•´å›å¤ä»¥ä¾¿æ·»åŠ åˆ°å†å²
                punctuation = {",", "ï¼Œ", ".", "ã€‚", "?", "ï¼Ÿ", "!", "ï¼", ";", "ï¼›", ":", "ï¼š", "\n"}

                try:
                    async for char in chat_stream(message_history):
                        # å®æ—¶æ¨æµæ–‡å­—
                        await websocket.send_json({"type": "text-update", "content": char})

                        sentence_buffer += char
                        full_response += char

                        # æ–­å¥
                        if char in punctuation:
                            if len(sentence_buffer.strip()) > 1:
                                print(f"ğŸ—£ï¸ [{client_id}] Synthesizing: {sentence_buffer}")
                                audio_base64 = await text_to_speech(sentence_buffer)

                                if audio_base64:
                                    await websocket.send_json({
                                        "type": "audio-chunk",
                                        "content": audio_base64
                                    })
                                sentence_buffer = ""

                    # å¤„ç†å‰©ä½™æ–‡æœ¬
                    if sentence_buffer.strip():
                         print(f"ğŸ—£ï¸ [{client_id}] Synthesizing (Final): {sentence_buffer}")
                         audio_base64 = await text_to_speech(sentence_buffer)
                         if audio_base64:
                            await websocket.send_json({
                                "type": "audio-chunk",
                                "content": audio_base64
                            })

                    # å°†åŠ©æ‰‹å›å¤æ·»åŠ åˆ°å¯¹è¯å†å²
                    if full_response.strip():
                        add_to_history("assistant", full_response.strip())
                        print(f"ğŸ“ [{client_id}] Added assistant response to history ({len(full_response)} chars)")

                except Exception as e:
                    print(f"âŒ LLM/TTS Process Error: {e}")
                    await websocket.send_json({"type": "text-update", "content": f"\n[Error: {str(e)}]"})

                await websocket.send_json({"type": "status", "content": "idle"})

    except WebSocketDisconnect:
        print(f"ğŸ‘‹ Client {client_id} disconnected")
    except Exception as e:
        print(f"âŒ WebSocket Error: {e}")
        try:
            await websocket.close()
        except:
            pass